[{"id":0,"title":"Character Recognizer - A CNN Model","author":"Mitsuki Youko","date_created":"2025-04-19","tag":"projects","blurb":"The process of training a CNN (in gradual steps) to recognize my 5 OCs.","content":"\n## Overview\n\nAs I'm looking to build my portfolio as a \"Jack of All Trades\", AI was a topic that was recommended to me.\n\nAfter some research, it seemed that a good beginner project would be the [Cats Vs Dogs Project](https://www.kaggle.com/c/dogs-vs-cats), where you train a model from a clean slate where it knows nothing about anything, and you teach it to differentiate between Cats and Dogs.\n\nThe idea is that you have your cat images in a folder labeled Cats and your dog images in a folder labeled Dogs and you create a Convolutional Neural Network (CNN) composed of different layers so that it keeps looping through your images to learn the characteristics of a cat and dog, etc.\n\nSince I am very passionate about my [personal project](https://mitsukiyouko555.wixsite.com/portfolio/personal-project), I always take any chance I could to involve my characters in whatever non-personal project thing I'm working on - so I figured, why not create a CNN that is able to differentiate between my 5 Main Characters?\n\n---\n\n## Issues: \n\n### 1. Small Dataset\n\nThe Cats vs Dogs dataset is HUGE at over 25,000 Images to train on. I draw my ocs pretty inconsistently lol... I mainly draw Maxus and Hydra and don't draw the others as much.\n\nAs such, I will have to draw an even amount of art per character.\n\nBut to reduce the time that it takes, I'm taking a ground up approach.\n\nFirst, I will train the CNN on the images of ONLY my characters' eyes - no background/transparent background.\n\nThen I will validate it by drawing a few more \"eyes only\" drawings and see if the model can correctly predict which set of eyes belong to which character.\n\nThen I will do the same with just the headshots of my characters, and then separately, do the same for full body shots.\n\nAs a final step, I will include multi-character images and have the model predict which character(s) are in the image.\n\n\n### 2. Image Size\n\nWhen training neural networks, it is strongly advised that the images be in the same size.\n\nTherefore, for the headshots, the images will be wider than they are tall but once I've decided on a fixed size, I will draw all the eyes-only pics in that one size only.\n\nThe same idea applies for the headshots which will be square.\n\nThe Full Body Images will be taller than they are wide, but of course, at the same consistent image size.\n\nThe Multi-Lable ones (the ones where the will be one or more characters in an image) will be a standard HD size (1920x1080) and will be shrunk down in correct proportions, if needed, when training the data.\n\n### 3. Image Variety\n\nIts important for there to be variety in terms of the background, otherwise the model might associate certain backgrounds with certain characters.\n\nSo I will need to build a dataset that has characters with no background, characters with a solid color or gradient/simple background, and characters with complex backgrounds.\n\nI also had the idea of animating some of these images - specifically for the eyes and headshots and MAYBE for a few of the fullbody ones as well and exporting it as png sequence so that it can have more data without me doing too much extra work.\n\n---\n\n### Timeline\n\nThis project will take at LEAST a few months if not more - but mainly because I need to create my dataset. If I were grabbing images off the internet, it would be way faster.. But because I have what eventually amounts to at least a hundred images to draw, (and I draw slow), it would take a while.\n\nWith Gemini's help and guidance, I suspect the actual coding of it is not that hard, but going through and typing it out line by line, tweaking it and really understanding what the code does and experimenting with it is going to be fun!\n\nI anticipate coming out of this project with a bunch of art created, as well as a cool CNN Model that can tell my characters apart.\n\n---\n\n### Research\n\n### Issues:\n- imports not importing (specifically keras.) fix: https://stackoverflow.com/questions/78998877/import-tensorflow-keras-callbacks-import-earlystopping-modelcheckpoint-could-n\n\nCalling Keras via `from keras.src.callbacks import xyz` instead of keras.callbacks\n\n#### Phase 1 - Eyes Only\n\n\n#### Phase 2 - Headshot Only\n\n\n\n#### Phase 3 - Full Body Only\n\n\n\n#### Phase 4 - Multi-Label (Multiple Characters)\n\n\n### Outcome and Results","folderName":"CharacterRecognizer"},{"id":1,"title":"How I Almost Got Hacked","author":"Mitsuki Youko","date_created":"2025-03-30","tag":"cyandden","blurb":"A cautionary tale about how, despite knowing the signs, I still ALMOST got hacked.","content":"\n# Infographic goes here... (WIP)","folderName":"HowIAlmostGotHacked"},{"id":2,"title":"Introducing Cy and Den","author":"Mitsuki Youko","date_created":"2025-03-27","tag":"misc","blurb":"Introducing Cyanscythe (Cy) and Goldenmage (Den).","content":"\n### What is / Who are CyanScythe (Cy) and GoldenMage (Den)?\n\nI love drawing and creating characters and figured... Why not mash that and what I learn in Ethical Hacking together?\nThat gave me the idea of drawing infographics whenever I learned something that could be infographic-worthy.\n \nSince I needed a name for my blog I just randomly came up with the word CyanScythe and created a character based off of that which I thought would be cool as an attacker type character. Then I thought \"Well attacker = red team.. so I'll need a \"defender\" and so I created GoldenMage.\n​\nIssue was that their color schemes were that of the opposing team.. but CyanScythe was such a cool name that I decided to make it so that she has magenta eyes and when she \"attacks\" with her scythe, it will turn red - thus giving her a red team vibe, despite the fact that her color scheme was cyan.\n \nDesign-wise, GoldenMage was a bit easier though I originally imagined his color scheme to be red and gold but since he is on the blue team, I gave him blue accessories. His powers are also blue to give off the blue team vibe.\n​\nNot only that, but a good theme here is that their designs can represent how important it is for red teamers to learn how to defend against cyber attacks and blue teamers to learn how attackers would attack, forming a good purple team - since they have colors of the opposing team.\n​\nIn the CyanScythe and GoldenMage Infographics, Cy will be presenting things from a Red Team Perspective while Den will be presenting things from a Blue Team Perspective.\n\nYou may also see a few comics about the both of them, if I happen to have a topic that can effectively be told in comic format.\n\nHope you enjoy the blog!\n\n---\n\n#### Cy's Character and Weapon Designs:\n\nWhen in Neutral mode, Cy's scythe is blue but it turns red when she is attacking.\n\n![Cy Neutral Mode](assets/content/IntroCyAndDen/img/Cy%20Neutral%20Mode.jpg)\n![Cy Attacker Mode](assets/content/IntroCyAndDen/img/Cy%20Attacker%20Mode.jpg)\n\n#### Den's Character and Weapons Design:\n\nDen's Barriers are not just for defensive purposes - he can use them to attack as well!\n\n![Den](assets/content/IntroCyAndDen/img/Den.jpg)\n![Den Weapon Design](assets/content/IntroCyAndDen/img/Den%20Weapons%20Design.png)\n","folderName":"IntroCyAndDen"},{"id":3,"title":"Pi Hole DNS Script","author":"Mitsuki Youko","date_created":"2025-04-19","tag":"scripts","blurb":"A Script to point your Linux Desktops to your Raspberry Pi's Pi Hole.","content":"\n## Note: This script assumes you have a Raspberry Pi and that you have Pi Hole Set up on your Raspberry Pi Already.\n\nThis script ensures that your Linux Desktop is pointed at your Pi Hole for DNS.\n\nIf you anticipate running this script for multiple machines, I would recommend deploying it via something like Ansible/Salt/Puppet or some other automation of that nature.\n\n[Here](https://github.com/mitsukiyouko555/saltstack), I used Saltstack to deploy it to my VMs.\n\nThis does not appear to work on Ubuntu SERVERS but it does work on Ubuntu Desktop, as well as Kali Linux.\n\nThe reason it does not work on Ubuntu servers is due to the difference in syntax when getting the connection name to show up.\n\n![PiDnsScript](assets/content/PiDnsScript/img/script.png)\n\n\n## Line By Line Breakdown:\n\n---\n\n### 1. #!/bin/bash\n\n^ This is what is known as the Shebang. It tells Linux what binary or command to use when running the program.\nIn this case, as we are coding in bash, this tells Linux that our bash is in the /bin/bash directory.\n\n---\n\n### 2. con=$(nmcli -t -f NAME connection show)\n\n![2](assets/content/PiDnsScript/img/2.jpg)\n\n^ The command shows the list of network connections that your machine has, such as eth0, for example..\nFor VMs, there's generally a few different connections.\n\nThis line is important because the connection NAME for each vm may vary and to point it at the DNS, we need the right name..\n\nFor example, one Ubuntu VM may have eth98 while another Ubuntu VM, while the OS is the same, may have a different name, such as eth07 - so this value cannot be hardcoded.\n\n---\n\n### 3. while IFS= read -r line; do\n\n^ This is similar to a while loop in that it loops though all the results and gets each line\n\n---\n\n### 4. #echo \"Connection: $line\"\n\n^ This was for testing purposes - to ensure that the results of the variable \"line\" was what I expected it to be.\n\n---\n\n### 5. nmcli con mod \"$line\" ipv4.ignore-auto-dns yes\n\n![5](assets/content/PiDnsScript/img/5.jpg)\n\n^ This line is modifying the output of the line that we got from running \"nmcli -t -f NAME connection show\" so it basically says for every connection that is being listed, Ignore the automatically assigned DNS (because we want it to point to the one we are setting manually.)\n\n---\n\n### 6. nmcli con mod \"$line\" ipv4.dns \"<Raspberry Pi's IP Address> 8.8.8.8 1.1.1.1\"\n\n![6](assets/content/PiDnsScript/img/6.jpg)\n\n^ This says modify the connection in the line variable and update the IPV4 DNS to point to our Raspberry Pi's IP address - thus making it use Pi Hole for the DNS.\n\nIn addition to that, 8.8.8.8 and 1.1.1.1 are Google and Cloudflare's respective DNS's.\n\nThese are there as fall backs so that if your Pi Hole is down, you can at least still connect to the internet via Google/Cloudflare's DNS.\n\n---\n\n### 7. done <<< \"$con\"\n\n^ This means once it's looped through all the connections and applied the steps above, the while loop can be exited.\n\n---\n\n### 8. service NetworkManager restart\n\n![8](assets/content/PiDnsScript/img/8.jpg)\n\n^ This restarts the Network Manager service so that the new DNS settings will reflect properly.\n\n---\n\n### 9. cat /etc/resolv.conf\n\n![9](assets/content/PiDnsScript/img/9.jpg)\n\n^ This shows the contents of the /etc/resolv.conf file, which is where the DNS info is stored.\n\nThis is so that we can confirm that the settings have been set properly.\n","folderName":"PiDnsScript"},{"id":4,"title":"Running Dog Animation Critique","author":"Mitsuki Youko","date_created":"2025-04-03","tag":"misc","blurb":"Running Dog Anim Critique for Redditor u/remyisacutie.","content":"\n# (WIP)\n\n### Overview\n\nThis blogpost is a bit different than my others as I will be breaking down my animation and composting process for [this reddit post](https://www.reddit.com/r/animation/comments/1jqdx7c/ik_this_is_wrong_but_how_do_i_fix_it/) by u/remyisacutie.\n\nHere is u/remyisacutie's original animation:\n\n![runningdog](assets/content/RunningDog/img/runningdog.mp4)\n\nHere are my initial thoughts on it:\n\n1. Dog's eyes are too static, introduce some blink\n2. Belly flops around a bit toooo much.. its like his ribs are moving - seems slightly unnatural.. if he just has a fat belly, the flop should be lower. (imo)\n3. Legs are good but not quite on the ground\n4. No shadow\n5. Cloud moving in different directions.. i guess that kinda works but if there's wind thats impacting the clouds that much, the trees would be affected a little too..\n6. Ears, tail, and legs are actually quite good!\n7. Tongue looks like its being swung forward.. doesn't quite match the running direction i feel...\n8. Tail is decent but it gets a little bit longer near the end.. (I struggle with that sometimes when I animate hair XD)\n9. Weight looks like it is on all 4 legs at the same time... I feel that when landing, weight should be on the front legs... this can probs be fixed simply by transforming and tilting the whole dog snout-side down just a tiny bit...\n10. Neck wrinkles are good but slightly off on timing it feels like..\n11. Looks like the path/ground is going z-axis yet the dog is running x axis which looks a bit.. strange i guess? but that might just be the placement cuz its not moving.. if the floor is moving, it would sell the thing a bit more...\n12. Imo the reason why it doesn't loop well is cus you probs need one more frame for some of the poses like the jump between the last and first frame is too big.\n13. Lighting.. The lighting changes too quickly on the dog like its running past a spotlight.. if its sunlight because its so far away, it wouldn't move on the dog that fast.\n14. Camera movement (maybe when landing, camera should follow the land a little - not TOO drastically but just a little movement helps)\n15. When looping always think back to HOW it loops. Do sketches first to see if it loops properly.. (before coloring or linearting). One trick is on the second half of the loop, use the frames in the first half in reversed order, then change some stuff in each so it doesn't just look like a copy\n\n---\n\n### Small Project Break Down..\n\n#### Animation Layers:\n1. Dog\n2. Shadow\n3. Foreground (ground and trees)\n    1. Make the ground long so that it you can move it x-axis. \n4. Background (clouds)\n5. Sky\n\n#### My Workflow for this critique demo:\n1. Sketch the dog running\n2. Sketch the dog's shadow\n3. Sketch the long bg on a different document. if animating, then composite it later. \n4. Lineart the bg\n5. Color the bg\n6. Lineart the dog\n7. Color the dog\n8. Color the Shadow\n9. Composite (Either baked in or after export.)\n\n#### I'll be making Two versions:\n1. Dog running with animated bg (BAKED IN Compositing)\n2. Dog running with animated bg (Compositing after Exporting)\n\n#### Composting tips:\n1. Export EACH animation layer separately so as to be able to add effects to them.. by layers I don't mean the dog's legs being on a different layer than its eyes... I mean Dog and its sublayers get exported as 1 png animation, bg gets exported as its own animation etc.. Anything you need to composite separately gets exported as its own png gif or image sequence.\n\n---\n\n### DEMO\n\nSo First thing's first.. gotta lay down the rough sketch of the dog model since its so long since I've drawn a dog.. (Had to rewatch the animal anatomy part of Marc Brunet's Digital Art School course that I bought a few years ago XD)\n\n![runningdogmodel](assets/content/RunningDog/img/Runningdogmodel.jpg)\n\nI used the straight line tool in CSP to make the line for the floor.\n\nThis is to make sure that when animating, the dog's paws won't go too high above or too low below the \"floor\". ideally it should land right on the line or as close to it as possible.\n\nI sketched the dog model just for reference and so I can make sure the animation stays on character.\n\nNow, so far drew a box around the dog so i can roughly tell where things are going to be placed...\n\n![dog-rectangle](assets/content/RunningDog/img/dog-rectangle.jpg)\n\nAnd then I animated the box to get the movement down..\n\n![blockout.gif](assets/content/RunningDog/img/blockout.gif)\n\n![roughplacement](assets/content/RunningDog/img/roughplacement.jpg)\n\nAs you can see, the frames are evenly spread out.. not very dynamic is it..?\n\nDon't worry, I will adjust the timing now after the rough movement has been placed..\n\nHere, I tend to play around - extend some frames, shorten others.. some people animate on 2's, 3's, 4's... that's way too much math for me loooll\n\nI animate based on feel.. so if you want to animate industry level stuff you might have to study how to animate on 2's etc. or whatever the industry uses :P\n\nI'm just a hobbyist and if it looks good to me, well that's really all I need XD\n\nSo after some re-timing, the frames now look like this:\n\n![frames_updated](assets/content/RunningDog/img/frames_updated.jpg)\n\nI also slightly adjusted the position and rotation of a few of the rectangles for a smoother flow..\n\n![blockout_framed](assets/content/RunningDog/img/blockout_framed.gif)\n\nSo the next phase of my rough sketch is going to be to move the bg around..\n\n[Watch this excellent video on how to use Keyframes for Camera Movement in CSP](https://www.youtube.com/watch?v=8F9eJjDkvtE)\n\nIf you don't use CSP, you can try to see if the software you use supports camera movements.\n\nOtherwise, if you want to do your camera movements during compositing instead, make sure you make the canvas size like roughly 0.5-1 inches bigger so that when compositing, your bg won't get awkwardly cut off when you reach the edge of the canvas.\n\nHere, I have the background animation folders within a larger folder and applied the keyframes to said folder.\n\nThe rectangle \"dog\" was outside the \"camera\" folder so as to not be affected by the camera keyframes.\n\nBackground camera keyframed to ever-so-slightly move up and down upon impact.\n\n![camera_keyframe](assets/content/RunningDog/img/camerakeyframe.jpg)\n\n![camera_keyframe_gif](assets/content/RunningDog/img/camera-keyframe.gif)\n\nThis is suuuuuper rough (bg timing is not very good either and should be fixed..).. Let's make this better and start sketching the dog :D\n\n![doglayer](assets/content/RunningDog/img/doglayer.jpg)\n\nImma start with the head..\n\n![dogheadske](assets/content/RunningDog/img/dogheadske.gif)\n\nWhen the dog lands, it'll crouch a bit so the head will be lower than it is now on those frames but for now, lets get the general movement down before worrying about that.\n\nAdding the neck guidelines / sketch:\n\n![dogheadneck](assets/content/RunningDog/img/dogheadneck.gif)\n\nAdding the body (mainly rib placement atm)\n\n![dogheadneckbod](assets/content/RunningDog/img/dogheadneckbod.gif)\n\nAdding the tail.. this one was a bit complicated.. had to fiddle with it for a bit..\n\n![dogtail](assets/content/RunningDog/img/dogtail.gif)\n\nOMG.. dogs are hard to draw lmaooo (not rly I just need more practice to get good at it XD)\n\nLooked up a dog running gif on the internet for some reference..\n\nOk.. I think Imma just stylize the legs instead of making them look realistic.. maybe gonna give him \"hoof-like\" legs instead cuz I'm too lazy to learn how to draw a dog just for a critique XD\n\n![doglegz](assets/content/RunningDog/img/doglegz.gif)\n\nAight, added the ears and snout..\n\n![runningdogskebgless](assets/content/RunningDog/img/runningdogskebgless.gif)\n\n\nChecking how it looks with the bg:\n\n![runningdogfullske](assets/content/RunningDog/img/runningdogfullske.gif)\n\nPretty good so far..\n\nI decided that it would be easier to just draw the dog lineart on a different animation layer than the sketch just in case I add more in betweens so made another layer for lineart.\n\n![dognewlayer](assets/content/RunningDog/img/dognewlayer.jpg)\n\nI will most likely color in the same animation layer (not same layer as the lineart but think of EACH frame in the animation layer as a folder and within that folder there are many more layers like lineart, color, etc.)\n\nSwitching gears, I decided to work on the background and created a new 1920 x 1080 CSP file. I then changed the canvas size so as to make it super long horizontally so as to make a revolving background. remember that the rightmost and leftmost section of your bg would need to be \"connectable\" with each other to sell that continuous effect when looping.\n\nI also expanded the canvas slightly vertically so as to maintain enough space for the camera's slight vertical pan when the dog jumps.\n\n![bgdoc](assets/content/RunningDog/img/bgdoc.jpg)\n\nI started with the clouds. \n\n![cloudline](assets/content/RunningDog/img/cloudline.jpg)\n\nI don't think there is wind strong enough to really make the clouds move drastically in any direction without it blowing the dog away (Clouds usually move rather slowly.. so unless the camera is focused on the clouds, you probs won't see it move much if at all.) so I'll keep the clouds static and have it wrap around in a revolving loop later.\n\n![cloudske](assets/content/RunningDog/img/cloudske.jpg)\n\nWhat I mean by revolve is if you take the right and leftmost cloud and you put them together, they should line up perfectly...\n\n![cloudwrap](assets/content/RunningDog/img/cloudwrap.jpg)\n\nThis is so that when you pan, you start with lining up the right side of this image to the right edge of the dog anim, and then you pan it by dragging it to the right slowly and smoothly. By the time it reaches the right side, there is no more art to continue it, you wrap it around and keyframe the image from its starting position coming in from the left..\n\nIt'll probably make more sense to see it in action... (Keep in mind this is still quite rough... but it gets the point across..)\n\nHere's the vid on youtube as the raw vid is too big for me to host on github unfortunately: [https://youtu.be/Z0TCPKRYMY8](https://youtu.be/Z0TCPKRYMY8).\n\nMoving on, I added some \"mountains\" in the bg as well as some bushes.\n\n(Ignore the bad bush/nature art XD I'm just half assing the bg rn since this critique is mainly about making the bg feel like it is moving properly and making the whole thing feel like its moving cohesively.)\n\nI then added some (badly drawn) grass that is supposed to go in front of the dog and the bushes. I'll animate the grass for maybe like 3-4 frames for a quick gentle sway, color it, then copy and paste it across the screen.\n\n![grass](assets/content/RunningDog/img/grass.jpg)\n\nThe dog's animation layer will go between the grass and the bushes.\n\nSo the grass will cover the dog when they overlap and the dog will cover the bushes when they overlap.\n\nAdditionally, this is the order of animation layers from moving the fastest to slowest in terms of panning:\n\n1. Grass (Fast when compared to the others but not SUPER fast either..)\n2. Dog (about the same speed as the grass)\n3. Ground/Bushes (slower than the dog)\n4. Mountains (slower than the bushes)\n5. Clouds (the slowest)\n\nHere is the badly animated grass (Ok enough for the critique tutorial.. def not up to par for my personal work tho lol)\n\n![badgrassanim](assets/content/RunningDog/img/badgrassanim.gif)\n\nHere it is colored:\n\n![grasscolored](assets/content/RunningDog/img/grasscolored.gif)\n\nHere it is with the grass strewn across the page.\n\n![grassfullanim](assets/content/RunningDog/img/grassfullanim.gif)\n\nAnd because we are only seeing parts of it at a time, it won't seem too repetitive.. otherwise ideally one should draw different strands of grass throughout at least half of it or draw a few chunks of grass and mix up the order for variety - but even like this it seems alright.. (if you don't look too closely)\n\nI had the grass in a different file so I straight up copied the grass animation folder into the running dog csp file.\n\nI have the already animated grass layer above the dog running layer and keygramed the grass layer like so:\n\n![dogAndGrassKeyframe](assets/content/RunningDog/img/dogAndGrassKeyframe.jpg)\n\nAnd now it looks like this:\n\n![dogAndGrass](assets/content/RunningDog/img/dogAndGrass.gif)\n\nThis is rough.. but will probs refine it later.\n\nColored and \"animated\" the clouds via transform and keyframes.\n\nNote - this is one of the reasons why I prefer to NOT bake in my composite...\n\n![mehclouds.gif](assets/content/RunningDog/img/mehclouds.gif)\n\n![mehclouds.jpg](assets/content/RunningDog/img/MehClouds.jpg)\n\nAs you can see, the clouds are basically forced to move at the same speed as the grass and it looks unnatural.. This is because the rest of the animation is within the 27 frames I have here. If i were to expand the number of frames, the dog and grass would be empty or the cutoff would be weird.\n\nBUT when compositing/video editing after exporting it out, you have a LOT more control over the individual elements and how fast or slow they move.\n\nYou can have the clouds move much slower and just keep looping the dog and the grass via copy and paste once you have the first loop down and make the duration long enough to cover the duration of the clouds. (I will demo that later)\n\nAdded the bg and the ground.. though as you can see, if the ground is static, it would look very strange and out of place as everything else is moving.\n\n![runningdogstaticfloor.gif](assets/content/RunningDog/img/runningdogstaticfloor.gif)\n\n![runningdogmovingfloor.gif](assets/content/RunningDog/img/runningdogmovingfloor.gif)\n\nNot sure why the bg is so choppy like that.. but we can probs fix that in compositing.. I think that's part of why I prefer exporting and then compositing it otherwise you get weird artifacts like this.\n\nIn any case, as you can see, the floor being moved along like a treadmill adds to the movement.\n\nThe clouds really bother me tho.. can't wait to fix them when I composite XD\n\nMoving on.. I fininshed the floor and the bushes and ended up putting them on the same layer.. I like how it came out.\n\nHere is a PNG of it.\n![bushesAndGround.png](assets/content/RunningDog/img/bushesAndGround.png)\n\n\nI don't like the mountains tho.. but that's cus I didn't try too hard since I have other projects to work on and this project was taking longer than anticipated XD\n\n![mountains.png](assets/content/RunningDog/img/mountains.png)\n\nAs I was experimenting, I found that layering the mountains and having the layers move at different speeds (further ones moving slower, closer ones moving faster) makes it look better.\n\n![runningDogWithBg.gif](assets/content/RunningDog/img/runningDogWithBg.gif)\n\nHowever, I still don't like how hard it is to time everything (when you have a lot of moving pieces like this) all within CSP. This would be much easier to do with say, Da Vinci Resolve, Adobe Premiere Pro, or some kind of video editor so that everything can have a different speed.\n\nRandom note: I shaded the grass a little but but because of how I did the keyframes, its too much work to implement it into the csp ver so I will use it in the Compositing ver.\n\nFor now, just know that the grass now looks like this:\n\n![shadedGrass.png](assets/content/RunningDog/img/shadedGrass.png)\n\nThough you probably can't tell from far away. (But don't worry, it'll be enlarged during the compositing phase.)\n\n![shadedGrass.gif](assets/content/RunningDog/img/shadedGrass.gif)\n\nSo now my background layers are all done (though in a real project I would add a lot more shading first) and consists of the following Layers (ordered by furthest to closest):\n\n1. Sky\n\n![sky.jpg](assets/content/RunningDog/img/sky.jpg)\n\n2. Clouds\n\n![clouds.png](assets/content/RunningDog/img/clouds.png)\n\n3. Mountains\n\n![mountains.png](assets/content/RunningDog/img/mountains.png)\n\n4. Ground / Bushes\n\n![bushesAndGround.png](assets/content/RunningDog/img/bushesAndGround.png)\n\n5. Grass\n\n![GrassNoBg.gif](assets/content/RunningDog/img/GrassNoBg.gif)\n\nAs you can see, only the Grass is actually animated.. the rest are all \"animated\" by literally transforming and moving the images around.\n\n\n\n<!--\n\nNote to self:\n- [x] animate the grass slowly blowing in the wind\n- [x] Color and shade the bushes\n- [x] Color and shade the mountains roughly\n- [ ] Add a layer of color for shading purposes on a blending mode layer on top of everything else. \n- [x] Use a gradient for the sky. \n- [ ] animate the shadow under the dog\n- [x] assemble the bg in the dog running file\n- [ ] Export everything separately\n- [ ] Assemble in Da Vinci Resolve\n- [ ] Compositing with the Reactor Plugin (Da Vinci Resolve Ver 19.0 ONLY) and Finishing Touches\n\n-->\n\n### Additional Resources:\n\nGood vid on Animating Backgrounds: [https://www.youtube.com/watch?v=M7yirNAyD5M](https://www.youtube.com/watch?v=M7yirNAyD5M)\n\n\n<!--\n\nnpm run server\nnpm run build\ngit add .\ngit commit -m \"update note\"\ngit push -u origin\nnpm run deploy \n\n-->\n","folderName":"RunningDog"}]